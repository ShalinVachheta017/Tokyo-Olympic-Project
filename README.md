# pyspark-olympic-data-etl


# 🏅 Tokyo Olympics 2021 - Azure Synapse & Analytics Project

## 📚 Project Overview
This project demonstrates how to build a complete data analytics pipeline for the Tokyo Olympics 2021 dataset using:
- **Azure Synapse Analytics**
- **Databricks (optional)**
- **SQL Data Analysis**

It covers medal distribution analysis, athlete participation, gender splits across disciplines, and country-wise sports performance.

---
## 🏗️ Architecture

- **Azure Data Lake Storage Gen2** — Storage for raw datasets.
- **Azure Synapse Analytics** — Data modeling and SQL queries.
- **Databricks (Optional)** — Data engineering and transformations.




---
## 🛠️ Technologies Used
| Tool                | Purpose                    |
| ------------------- | --------------------------- |
| Azure Synapse        | SQL Pools + Query Analytics  |
| Azure Data Lake Gen2 | Data Storage                 |
| Databricks (Optional)| Data Engineering & Cleaning |


---
## 🚀 Steps to Reproduce
1. Upload dataset to Azure Data Lake Storage Gen2.
2. Create external tables in Azure Synapse using serverless SQL pools.
3. Write SQL queries to explore and analyze medals, athletes, entries, and coaches data.
4.(Optional) Use Databricks notebooks for any advanced transformations.

---
## 📊 Key Insights
- Medal distribution and efficiency by country.
- Male vs Female participation ratio per sport.
- Medal efficiency (Medals per Athlete).
- Coach to Athlete ratios across countries.

---
## ⚡ Learning Highlights
- Building **serverless SQL pools** inside Azure Synapse.
- Data modeling using external tables and managed tables.
- Authenticating between services (Managed Identity / SQL Auth).
- Query optimization for large datasets.

---
## 📍 About the Author
> Project by **[Shalin Vachheta](https://github.com/ShalinVachheta017)**  
> Focused on AI, Data Engineering, Analytics, and Cloud Technologies.  
> Building real-world scalable solutions.

---
✅ **Professional, clean, and focused** on your data engineering + analytics work.

---
